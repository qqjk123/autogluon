# v2 resnet
# Resnet - ä¼˜åŒ–ç‰ˆ (é€‚ç”¨äº A100)
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from tqdm import tqdm
import torch.nn.functional as F

# å¯¼å…¥ MedMNIST å’Œ MONAI ç›¸å…³åº“
import medmnist
from medmnist import INFO

from monai.data import list_data_collate
from monai.transforms import (
    Compose,
    ScaleIntensityd,
    ToTensord,
    Resized,
    RandRotate90d,   # æ–°å¢ï¼šæ•°æ®å¢å¼º
    RandAffined,      # æ–°å¢ï¼šæ•°æ®å¢å¼º
    RandFlipd,        # æ–°å¢ï¼šæ•°æ®å¢å¼º
)
from monai.networks.nets import DenseNet121, EfficientNetBN, ResNet, ViT
from monai.metrics import ROCAUCMetric
from monai.networks.nets.resnet import get_inplanes

# ======================================================================================
# 1. é…ç½®åŒºåŸŸ (å¢å¼ºç‰ˆ)
# ======================================================================================
# 'organmnist3d', 'nodulemnist3d', 'adrenalmnist3d', 'fracturemnist3d', 'vesselmnist3d', 'synapsemnist3d'
class Config:
    # --- å®éªŒä¸æ•°æ®é…ç½® ---
    DATA_FLAG = 'nodulemnist3d'
    MODEL_NAME = 'ResNet50'
    EXPERIMENT_NAME = f"{MODEL_NAME}_{DATA_FLAG}_Optimized_v1" # ä¸ºæœ¬æ¬¡å®éªŒå‘½å
    
    # --- è®­ç»ƒè¶…å‚æ•° ---
    NUM_EPOCHS = 30           # å¢åŠ è®­ç»ƒå‘¨æœŸï¼Œè®©æ¨¡å‹æœ‰æ›´å……åˆ†çš„æ—¶é—´å­¦ä¹ 
    BATCH_SIZE = 128          # A100 æ˜¾å­˜è¾ƒå¤§ï¼Œå¯ä»¥å°è¯•æ›´å¤§çš„ Batch Size
    LEARNING_RATE = 1e-3      # é…åˆå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåˆå§‹å­¦ä¹ ç‡å¯ä»¥è®¾é«˜ä¸€äº›
    WEIGHT_DECAY = 1e-5       # ä¸º AdamW è®¾ç½®æƒé‡è¡°å‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
    
    # --- ç¡¬ä»¶ä¸æ•ˆç‡é…ç½® ---
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    NUM_WORKERS = 16          # æ ¹æ®ä½ çš„ CPU å’Œ IO èƒ½åŠ›è°ƒæ•´
    USE_AMP = True            # å…³é”®ï¼šå¼€å¯è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)
    
    # --- æ¨¡å‹ä¿å­˜ ---
    MODEL_SAVE_DIR = "./saved_models"

# ======================================================================================
# 2. è¾…åŠ©å‡½æ•° (æ•°æ®åŠ è½½å’Œæ¨¡å‹å®šä¹‰)
# ======================================================================================
class MedMNIST3DWrapper(Dataset):
    def __init__(self, medmnist_dataset, transform):
        self.medmnist_dataset = medmnist_dataset
        self.transform = transform

    def __len__(self):
        return len(self.medmnist_dataset)

    def __getitem__(self, idx):
        image, label = self.medmnist_dataset[idx]
        
        # [ä¿æŒ] ä½¿ç”¨Numpyæ‰‹åŠ¨æ·»åŠ é€šé“ç»´åº¦
        if image.ndim == 3:
            image = np.expand_dims(image, axis=0) # (1, 28, 28, 28)
        
        data = {'image': image, 'label': label}
        
        if self.transform:
            data = self.transform(data)
            
        return data

def get_data_loaders(config):
    print(f"å‡†å¤‡æ•°æ®é›†: {config.DATA_FLAG}...")
    info = INFO[config.DATA_FLAG]
    DataClass = getattr(medmnist.dataset, f"{info['python_class']}")
    
    # å›¾åƒç›®æ ‡å°ºå¯¸
    target_spatial_size = (32, 32, 32)

    # [ä¼˜åŒ–] å¢å¼ºçš„è®­ç»ƒæ•°æ®å˜æ¢æµç¨‹
    train_transforms = Compose([
        ScaleIntensityd(keys="image"),
        Resized(keys="image", spatial_size=target_spatial_size, mode="trilinear", align_corners=False),
        # --- æ•°æ®å¢å¼º ---
        RandFlipd(keys="image", spatial_axis=[0, 1, 2], prob=0.5), # åœ¨ä¸‰ä¸ªè½´ä¸Šéšæœºç¿»è½¬
        RandRotate90d(keys="image", prob=0.5, max_k=3), # éšæœºæ—‹è½¬90åº¦
        RandAffined(
            keys='image',
            mode='bilinear',
            prob=0.8,
            spatial_size=target_spatial_size,
            rotate_range=(np.pi / 12, np.pi / 12, np.pi / 12), # æ—‹è½¬èŒƒå›´
            scale_range=(0.2, 0.2, 0.2), # ç¼©æ”¾èŒƒå›´
            padding_mode='border'
        ),
        # --- è½¬æ¢ä¸ºå¼ é‡ ---
        ToTensord(keys=["image", "label"], track_meta=False),
    ])

    # [ä¿æŒ] éªŒè¯å’Œæµ‹è¯•é›†ä¸éœ€è¦æ•°æ®å¢å¼ºï¼Œåªéœ€é¢„å¤„ç†
    val_test_transforms = Compose([
        ScaleIntensityd(keys="image"),
        Resized(keys="image", spatial_size=target_spatial_size, mode="trilinear", align_corners=False),
        ToTensord(keys=["image", "label"], track_meta=False),
    ])

    train_dataset_raw = DataClass(split='train', download=True)
    train_ds = MedMNIST3DWrapper(train_dataset_raw, train_transforms)
    
    val_dataset_raw = DataClass(split='val', download=True)
    val_ds = MedMNIST3DWrapper(val_dataset_raw, val_test_transforms)

    train_loader = DataLoader(
        train_ds, batch_size=config.BATCH_SIZE, shuffle=True,  
        num_workers=config.NUM_WORKERS, collate_fn=list_data_collate, pin_memory=True # pin_memory åŠ é€Ÿæ•°æ®åˆ°GPUçš„ä¼ è¾“
    )
    val_loader = DataLoader(
        val_ds, batch_size=config.BATCH_SIZE, shuffle=False,  
        num_workers=config.NUM_WORKERS, collate_fn=list_data_collate, pin_memory=True
    )
    
    print(f"æ•°æ®åŠ è½½å®Œæˆ. ä»»åŠ¡: {info['task']}, ç±»åˆ«æ•°: {len(info['label'])}")
    return train_loader, val_loader, info, target_spatial_size

def get_model(config, info, img_size):
    model_name, num_classes = config.MODEL_NAME, len(info['label'])
    print(f"åˆå§‹åŒ–æ¨¡å‹: {model_name}...")
    in_channels = 1 
    
    if model_name == 'DenseNet121':
        model = DenseNet121(spatial_dims=3, in_channels=in_channels, out_channels=num_classes)
    elif model_name == 'EfficientNet-B0':
        model = EfficientNetBN(model_name='efficientnet-b0', spatial_dims=3, in_channels=in_channels, num_classes=num_classes, pretrained=False)
    elif model_name == 'ResNet50':
        model = ResNet(block='bottleneck', layers=[3, 4, 6, 3], block_inplanes=get_inplanes(), spatial_dims=3, n_input_channels=in_channels, num_classes=num_classes)
    elif model_name == 'ViT':
        # æ³¨æ„: ViTå¯¹patch_sizeå’Œimg_sizeæœ‰è¦æ±‚ï¼Œéœ€ç¡®ä¿èƒ½æ•´é™¤
        patch_size = (8, 8, 8) if img_size[0] % 8 == 0 else (4, 4, 4)
        model = ViT(in_channels=in_channels, img_size=img_size, patch_size=patch_size, classification=True, num_classes=num_classes)
    else:
        raise ValueError(f"æ¨¡å‹ '{model_name}' ä¸è¢«æ”¯æŒ.")
    return model.to(config.DEVICE)


# ======================================================================================
# 3. è®­ç»ƒä¸è¯„ä¼°æ¨¡å— (ä¼˜åŒ–ç‰ˆ)
# ======================================================================================
def run_training(config, model, train_loader, val_loader, info):
    task = info['task']
    device = config.DEVICE

    loss_function = nn.CrossEntropyLoss() if task != 'multi-label, binary-class' else nn.BCEWithLogitsLoss()
    primary_metric_name = "Accuracy" if task != 'multi-label, binary-class' else "AUC"
    print(f"ä»»åŠ¡ä¸º {task}, ä½¿ç”¨ {loss_function.__class__.__name__}. ä¸»è¦è¯„ä¼°æŒ‡æ ‡: {primary_metric_name}.")
        
    # [ä¼˜åŒ–] ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)
    
    # [ä¼˜åŒ–] ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.NUM_EPOCHS, eta_min=1e-6)

    # [ä¼˜åŒ–] åˆå§‹åŒ–æ··åˆç²¾åº¦è®­ç»ƒçš„ GradScaler
    scaler = torch.cuda.amp.GradScaler(enabled=config.USE_AMP)
    
    best_metric, best_metric_epoch = -1, -1
    
    print(f"\n--- å¼€å§‹è®­ç»ƒ: {config.EXPERIMENT_NAME} ---")
    for epoch in range(config.NUM_EPOCHS):
        model.train()
        epoch_loss = 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config.NUM_EPOCHS} [è®­ç»ƒ]", unit="batch")
        for batch_data in progress_bar:
            # [ä¼˜åŒ–] ä½¿ç”¨ non_blocking=True åŠ é€Ÿæ•°æ®ä¼ è¾“
            inputs, labels = batch_data["image"].to(device, non_blocking=True), batch_data["label"].to(device, non_blocking=True)
            
            optimizer.zero_grad()
            
            # [ä¼˜åŒ–] ä½¿ç”¨ autocast ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿›è¡Œå‰å‘ä¼ æ’­
            with torch.cuda.amp.autocast(enabled=config.USE_AMP):
                outputs = model(inputs)
                if isinstance(loss_function, nn.CrossEntropyLoss):
                    labels = labels.squeeze(1).long()
                else:  
                    labels = labels.float()
                loss = loss_function(outputs, labels)
            
            # [ä¼˜åŒ–] ä½¿ç”¨ scaler è¿›è¡Œåå‘ä¼ æ’­å’Œä¼˜åŒ–å™¨æ­¥éª¤
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            epoch_loss += loss.item()
            progress_bar.set_postfix({"loss": f"{loss.item():.4f}", "lr": f"{optimizer.param_groups[0]['lr']:.6f}"})
        
        # [ä¼˜åŒ–] åœ¨æ¯ä¸ª epoch ç»“æŸåæ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        print(f"Epoch {epoch + 1} å¹³å‡è®­ç»ƒæŸå¤±: {epoch_loss / len(train_loader):.4f}")

        # --- éªŒè¯é˜¶æ®µ ---
        model.eval()
        auc_metric = ROCAUCMetric()
        all_val_outputs, all_val_labels = [], []
        with torch.no_grad():
            for val_data in tqdm(val_loader, desc=f"Epoch {epoch+1}/{config.NUM_EPOCHS} [éªŒè¯]", unit="batch"):
                val_images = val_data["image"].to(device, non_blocking=True)
                val_labels = val_data["label"].to(device, non_blocking=True)
                with torch.cuda.amp.autocast(enabled=config.USE_AMP):
                    val_outputs = model(val_images)
                all_val_outputs.append(val_outputs)
                all_val_labels.append(val_labels)

        all_val_outputs = torch.cat(all_val_outputs, dim=0)
        all_val_labels = torch.cat(all_val_labels, dim=0)

        # [ä¿æŒ] è¯„ä¼°é€»è¾‘ä¸å˜
        if task == 'multi-label, binary-class':
            val_probs = torch.sigmoid(all_val_outputs)
            auc_metric(y_pred=val_probs, y=all_val_labels.long())
            preds_class = val_probs > 0.5
            acc_result = (preds_class == all_val_labels.bool()).sum().item() / all_val_labels.numel()
        else:
            val_probs = torch.softmax(all_val_outputs, dim=1)
            val_labels_1d = all_val_labels.squeeze(1).long()
            num_classes = val_probs.shape[1]
            val_labels_onehot = F.one_hot(val_labels_1d, num_classes=num_classes).float()
            y_pred_classes = torch.argmax(all_val_outputs, dim=1)
            correct = (y_pred_classes == val_labels_1d).sum().item()
            acc_result = correct / val_labels_1d.numel()
            auc_metric(y_pred=val_probs, y=val_labels_onehot)
            
        auc_result = auc_metric.aggregate().item()
        print(f"Epoch {epoch + 1} éªŒè¯ -> AUC: {auc_result:.4f}, Accuracy: {acc_result:.4f}")

        current_metric = auc_result if primary_metric_name == "AUC" else acc_result
        if current_metric > best_metric:
            best_metric, best_metric_epoch = current_metric, epoch + 1
            os.makedirs(config.MODEL_SAVE_DIR, exist_ok=True)
            save_path = os.path.join(config.MODEL_SAVE_DIR, f"best_{config.EXPERIMENT_NAME}.pth")
            torch.save(model.state_dict(), save_path)
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! (åŸºäº {primary_metric_name}) å·²ä¿å­˜åˆ°: {save_path}")

    print(f"--- è®­ç»ƒå®Œæˆ ---")
    print(f"æœ€ä½³éªŒè¯ {primary_metric_name}: {best_metric:.4f} (åœ¨ Epoch {best_metric_epoch})")

# ======================================================================================
# 4. Test é›†è¯„ä¼° (ä¼˜åŒ–ç‰ˆ)
# ======================================================================================
@torch.no_grad()
def evaluate_on_test(config, info, img_size):
    print("\n========== å¼€å§‹ Test è¯„ä¼° ==========")

    # [ä¿æŒ] æµ‹è¯•é›†ä½¿ç”¨ä¸éªŒè¯é›†ç›¸åŒçš„å˜æ¢
    test_transforms = Compose([
        ScaleIntensityd(keys="image"),
        Resized(keys="image", spatial_size=img_size, mode="trilinear", align_corners=False),
        ToTensord(keys=["image", "label"], track_meta=False),
    ])

    DataClass = getattr(medmnist.dataset, f"{info['python_class']}")
    test_dataset_raw = DataClass(split="test", download=True)
    test_ds = MedMNIST3DWrapper(test_dataset_raw, test_transforms)

    test_loader = DataLoader(
        test_ds, batch_size=config.BATCH_SIZE, shuffle=False,
        num_workers=config.NUM_WORKERS, collate_fn=list_data_collate, pin_memory=True
    )

    model = get_model(config, info, img_size)
    best_ckpt_path = os.path.join(config.MODEL_SAVE_DIR, f"best_{config.EXPERIMENT_NAME}.pth")
    
    if not os.path.exists(best_ckpt_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ '{best_ckpt_path}'ã€‚è¯·å…ˆå®Œæˆè®­ç»ƒã€‚")
        return

    model.load_state_dict(torch.load(best_ckpt_path, map_location=config.DEVICE))
    model.eval()

    all_outputs, all_labels = [], []
    for batch in tqdm(test_loader, desc="Test æ¨æ–­", unit="batch"):
        imgs = batch["image"].to(config.DEVICE, non_blocking=True)
        labels = batch["label"].to(config.DEVICE, non_blocking=True)
        # [ä¼˜åŒ–] åœ¨è¯„ä¼°æ—¶ä¹Ÿä½¿ç”¨ AMPï¼Œå¯ä»¥åŠ é€Ÿ
        with torch.cuda.amp.autocast(enabled=config.USE_AMP):
            logits = model(imgs)
        all_outputs.append(logits)
        all_labels.append(labels)

    all_outputs = torch.cat(all_outputs, dim=0)
    all_labels = torch.cat(all_labels, dim=0)

    labels_1d = all_labels.squeeze(1).long()
    preds_cls = torch.argmax(all_outputs, dim=1)
    accuracy = (preds_cls == labels_1d).float().mean().item()

    probs = torch.softmax(all_outputs, dim=1)
    one_hot = F.one_hot(labels_1d, num_classes=probs.shape[1]).float()
    auc_metric = ROCAUCMetric()
    auc_metric(y_pred=probs, y=one_hot)
    auc = auc_metric.aggregate().item()

    print(f"\nâœ… Test ç»“æœ ({config.EXPERIMENT_NAME}) â†’  ACC: {accuracy:.4f} | AUC: {auc:.4f}")
    print("=====================================")


# ======================================================================================
# 5. ä¸»æ‰§è¡Œå‡½æ•°
# ======================================================================================
def main():
    config = Config()
    print("="*50)
    print(f"é…ç½®: Dataset={config.DATA_FLAG}, Model={config.MODEL_NAME}, Device={config.DEVICE}")
    print(f"å®éªŒåç§°: {config.EXPERIMENT_NAME}")
    print(f"è¶…å‚æ•°: Epochs={config.NUM_EPOCHS}, Batch Size={config.BATCH_SIZE}, LR={config.LEARNING_RATE}, AMP={'å¯ç”¨' if config.USE_AMP else 'ç¦ç”¨'}")
    print("="*50 + "\n")

    train_loader, val_loader, info, img_size = get_data_loaders(config)
    model = get_model(config, info, img_size)
    
    run_training(config, model, train_loader, val_loader, info)
    
    # è®­ç»ƒç»“æŸåï¼Œè‡ªåŠ¨åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹
    evaluate_on_test(config, info, img_size)
    
    print("\næ‰€æœ‰ä»»åŠ¡å®Œæˆ!")

if __name__ == "__main__":
    main()
