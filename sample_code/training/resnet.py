# Resnet 
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from tqdm import tqdm

import medmnist
from medmnist import INFO

from monai.data import list_data_collate
# [æœ€ç»ˆä¿®å¤] ç§»é™¤æ‰€æœ‰è‡ªåŠ¨å¤„ç†é€šé“çš„Transform
from monai.transforms import (
    Compose,
    ScaleIntensityd,
    ToTensord,
    ToTensor,
    Resized
)
from monai.networks.nets import DenseNet121, EfficientNetBN, ResNet, ViT
from monai.metrics import ROCAUCMetric, get_confusion_matrix, compute_confusion_matrix_metric
from monai.networks.nets.resnet import get_inplanes
import torch.nn.functional as F

# ======================================================================================
# 1. é…ç½®åŒºåŸŸ
# ======================================================================================
#'organmnist3d', 'nodulemnist3d', 'adrenalmnist3d', 'fracturemnist3d', 'vesselmnist3d', 'synapsemnist3d'
class Config:
    DATA_FLAG = 'adrenalmnist3d'
    MODEL_NAME = 'ResNet50'
    NUM_EPOCHS = 15
    BATCH_SIZE = 64
    LEARNING_RATE = 1e-4
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    NUM_WORKERS = 16
    MODEL_SAVE_DIR = "./saved_models"

# ======================================================================================
# 2. è¾…åŠ©å‡½æ•° (æ•°æ®åŠ è½½å’Œæ¨¡å‹å®šä¹‰)
# ======================================================================================
class MedMNIST3DWrapper(Dataset):
    def __init__(self, medmnist_dataset, transform):
        self.medmnist_dataset = medmnist_dataset
        self.transform = transform

    def __len__(self):
        return len(self.medmnist_dataset)

    def __getitem__(self, idx):
        image, label = self.medmnist_dataset[idx]
        
        # [æœ€ç»ˆä¿®å¤] ä½¿ç”¨Numpyæ‰‹åŠ¨æ·»åŠ é€šé“ç»´åº¦ï¼Œç¡®ä¿å½¢çŠ¶æ­£ç¡®
        # åŸå§‹å½¢çŠ¶: (28, 28, 28) -> æ–°å½¢çŠ¶: (1, 28, 28, 28)
        if image.ndim == 3:
            image = np.expand_dims(image, axis=0)
        
        # å°†å¤„ç†å¥½çš„Numpyæ•°ç»„æ”¾å…¥å­—å…¸ï¼Œä»¥ä¾›åç»­transformä½¿ç”¨
        data = {'image': image, 'label': label}
        
        # åº”ç”¨å‰©ä½™çš„transformï¼ˆç¼©æ”¾å’Œè½¬ä¸ºå¼ é‡ï¼‰
        if self.transform:
            data = self.transform(data)
            
        return data

def get_data_loaders(config):
    print(f"å‡†å¤‡æ•°æ®é›†: {config.DATA_FLAG}...")
    info = INFO[config.DATA_FLAG]
    DataClass = getattr(medmnist.dataset, f"{info['python_class']}")
    img_size = (28, 28, 28)
    
    # [æœ€ç»ˆä¿®å¤] ç®€åŒ–Transformæµç¨‹ï¼Œç§»é™¤æ‰€æœ‰é€šé“å¤„ç†æ“ä½œ
    transforms = Compose([
        ScaleIntensityd(keys="image"),
        Resized(
        keys="image",                 # string or list both fine
        spatial_size=(32, 32, 32),    # make each axis â‰¥32 so DenseNet works
        mode="trilinear",             # interpolation for images
        align_corners=False           # optional, safe for most cases
        ),
        ToTensord(keys=["image", "label"], track_meta=False),
    ])

    train_dataset_raw = DataClass(split='train', download=True)
    train_ds = MedMNIST3DWrapper(train_dataset_raw, transforms)
    
    val_dataset_raw = DataClass(split='val', download=True)
    val_ds = MedMNIST3DWrapper(val_dataset_raw, transforms)

    train_loader = DataLoader(
        train_ds, batch_size=config.BATCH_SIZE, shuffle=True, 
        num_workers=config.NUM_WORKERS, collate_fn=list_data_collate
    )
    val_loader = DataLoader(
        val_ds, batch_size=config.BATCH_SIZE, shuffle=False, 
        num_workers=config.NUM_WORKERS, collate_fn=list_data_collate
    )
    
    # æ³¨æ„ï¼šæ‚¨çš„ç¯å¢ƒå°†organmnist3dè¯†åˆ«ä¸ºmulti-classï¼Œä»£ç å°†æ®æ­¤è°ƒæ•´ã€‚
    # è¿™å¯èƒ½ä¸å®˜æ–¹æ–‡æ¡£ä¸ç¬¦ï¼Œæˆ–æ˜¯ç”±äºmedmniståº“ç‰ˆæœ¬è¾ƒæ—§ã€‚
    print(f"æ•°æ®åŠ è½½å®Œæˆ. ä»»åŠ¡: {info['task']}, ç±»åˆ«æ•°: {len(info['label'])}")
    return train_loader, val_loader, info, img_size

def get_model(config, info, img_size):
    model_name, num_classes = config.MODEL_NAME, len(info['label'])
    print(f"åˆå§‹åŒ–æ¨¡å‹: {model_name}...")
    in_channels = 1 # æˆ‘ä»¬æ‰‹åŠ¨ä¿è¯äº†è¾“å…¥é€šé“ä¸º1
    
    if model_name == 'DenseNet121':
        model = DenseNet121(spatial_dims=3, in_channels=in_channels, out_channels=num_classes)
    elif model_name == 'EfficientNet-B0':
        model = EfficientNetBN(model_name='efficientnet-b0', spatial_dims=3, in_channels=in_channels, num_classes=num_classes, pretrained=False)
    elif model_name == 'ResNet50':
        model = ResNet(block='bottleneck', layers=[3, 4, 6, 3], block_inplanes=get_inplanes(), spatial_dims=3, n_input_channels=in_channels, num_classes=num_classes)
    elif model_name == 'ViT':
        model = ViT(in_channels=in_channels, img_size=img_size, patch_size=(7, 7, 7), classification=True, num_classes=num_classes)
    else:
        raise ValueError(f"æ¨¡å‹ '{model_name}' ä¸è¢«æ”¯æŒ.")
    return model.to(config.DEVICE)


# ======================================================================================
# 3. è®­ç»ƒä¸è¯„ä¼°æ¨¡å—
# ======================================================================================
def run_training(config, model, train_loader, val_loader, info):
    task = info['task']
    device = config.DEVICE

    if task == 'multi-label, binary-class':
        loss_function = nn.BCEWithLogitsLoss()
        primary_metric_name = "AUC"
        print("ä»»åŠ¡ä¸ºå¤šæ ‡ç­¾åˆ†ç±», ä½¿ç”¨ BCEWithLogitsLoss. ä¸»è¦è¯„ä¼°æŒ‡æ ‡: AUC.")
    else: # æ‚¨çš„ç¯å¢ƒä¼šè¿›å…¥æ­¤åˆ†æ”¯
        loss_function = nn.CrossEntropyLoss()
        primary_metric_name = "Accuracy"
        print(f"ä»»åŠ¡ä¸º {task}, ä½¿ç”¨ CrossEntropyLoss. ä¸»è¦è¯„ä¼°æŒ‡æ ‡: Accuracy.")
        
    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)
    best_metric, best_metric_epoch = -1, -1
    
    print(f"\n--- å¼€å§‹è®­ç»ƒæ¨¡å‹: {config.MODEL_NAME} on {config.DATA_FLAG} ---")
    for epoch in range(config.NUM_EPOCHS):
        model.train()
        epoch_loss = 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config.NUM_EPOCHS} [è®­ç»ƒ]", unit="batch")
        for batch_data in progress_bar:
            inputs, labels = batch_data["image"].to(device), batch_data["label"].to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            
            if isinstance(loss_function, nn.CrossEntropyLoss):
                labels = labels.squeeze(1).long()
            else: 
                labels = labels.float()
                
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
            progress_bar.set_postfix({"loss": f"{loss.item():.4f}"})
        
        print(f"Epoch {epoch + 1} å¹³å‡è®­ç»ƒæŸå¤±: {epoch_loss / len(train_loader):.4f}")

        model.eval()
        auc_metric = ROCAUCMetric()
        all_val_outputs, all_val_labels = [], []
        with torch.no_grad():
            for val_data in tqdm(val_loader, desc=f"Epoch {epoch+1}/{config.NUM_EPOCHS} [éªŒè¯]", unit="batch"):
                val_images = val_data["image"].to(device)
                val_labels = val_data["label"].to(device)
                val_outputs = model(val_images)
                all_val_outputs.append(val_outputs)
                all_val_labels.append(val_labels)
        all_val_outputs = torch.cat(all_val_outputs, dim=0)
        all_val_labels = torch.cat(all_val_labels, dim=0)

        if task == 'multi-label, binary-class':
            val_probs = torch.sigmoid(all_val_outputs)
            auc_metric(y_pred=val_probs, y=all_val_labels.long())
            preds_class = val_probs > 0.5
            acc_result = (preds_class == all_val_labels.bool()).sum().item() / all_val_labels.numel()
        else: # æ‚¨çš„ç¯å¢ƒä¼šè¿›å…¥æ­¤åˆ†æ”¯
            val_probs = torch.softmax(all_val_outputs, dim=1)      # (N, C)
            val_labels_1d = all_val_labels.squeeze(1).long()       # (N,)
            
            # å…³é”®ï¼šæŠŠ 1-D label è½¬ one-hotï¼Œè½¬æˆ float ä¾› auc è®¡ç®—
            num_classes = val_probs.shape[1]
            val_labels_onehot = F.one_hot(val_labels_1d, num_classes=num_classes).float()
            
            # Accuracy ä»ç”¨ 1-D label è®¡ç®—
            y_pred_classes = torch.argmax(all_val_outputs, dim=1)
            correct = (y_pred_classes == val_labels_1d).sum().item()
            acc_result = correct / val_labels_1d.numel()
            
            # AUC ç”¨ one-hot label
            auc_metric(y_pred=val_probs, y=val_labels_onehot)
            
        auc_result = auc_metric.aggregate().item()
        print(f"Epoch {epoch + 1} éªŒè¯ -> AUC: {auc_result:.4f}, Accuracy: {acc_result:.4f}")

        current_metric = auc_result if primary_metric_name == "AUC" else acc_result
        if current_metric > best_metric:
            best_metric, best_metric_epoch = current_metric, epoch + 1
            os.makedirs(config.MODEL_SAVE_DIR, exist_ok=True)
            save_path = os.path.join(config.MODEL_SAVE_DIR, f"best_{config.MODEL_NAME}_{config.DATA_FLAG}.pth")
            torch.save(model.state_dict(), save_path)
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! (åŸºäº {primary_metric_name}) å·²ä¿å­˜åˆ°: {save_path}")

    print(f"--- è®­ç»ƒå®Œæˆ ---")
    print(f"æœ€ä½³éªŒè¯ {primary_metric_name}: {best_metric:.4f} (åœ¨ Epoch {best_metric_epoch})")

# ======================================================================================
# 4. Test é›†è¯„ä¼°
# ======================================================================================
@torch.no_grad()
def evaluate_on_test(config, info, img_size):
    print("\n========== å¼€å§‹ Test è¯„ä¼° ==========")

    # -------- 1. ç»„è£…ä¸è®­ç»ƒåŒæ ·çš„ transforms --------
    test_transforms = Compose([
        ScaleIntensityd(keys="image"),
        Resized(keys="image", spatial_size=(32, 32, 32),
                mode="trilinear", align_corners=False),
        ToTensord(keys=["image", "label"], track_meta=False),
    ])

    # -------- 2. åŠ è½½ Test æ•°æ® --------
    DataClass = getattr(medmnist.dataset, f"{info['python_class']}")
    test_dataset_raw = DataClass(split="test", download=True)
    test_ds = MedMNIST3DWrapper(test_dataset_raw, test_transforms)

    test_loader = DataLoader(
        test_ds,
        batch_size=config.BATCH_SIZE,
        shuffle=False,
        num_workers=config.NUM_WORKERS,
        collate_fn=list_data_collate,
    )

    # -------- 3. æ„å»ºæ¨¡å‹å¹¶è½½å…¥æœ€ä½³æƒé‡ --------
    model = get_model(config, info, img_size)
    best_ckpt = os.path.join(config.MODEL_SAVE_DIR,
                             f"best_{config.MODEL_NAME}_{config.DATA_FLAG}.pth")
    model.load_state_dict(torch.load(best_ckpt, map_location=config.DEVICE))
    model.eval()

    # -------- 4. æ¨æ–­å¹¶æ”¶é›†è¾“å‡º --------
    all_outputs, all_labels = [], []
    for batch in tqdm(test_loader, desc="Test æ¨æ–­", unit="batch"):
        imgs = batch["image"].to(config.DEVICE)
        labels = batch["label"].to(config.DEVICE)
        logits = model(imgs)
        all_outputs.append(logits)
        all_labels.append(labels)

    all_outputs = torch.cat(all_outputs, dim=0)         # (N, C)
    all_labels  = torch.cat(all_labels,  dim=0)         # (N, 1)

    # -------- 5. è®¡ç®— Accuracy --------
    labels_1d = all_labels.squeeze(1).long()
    preds_cls  = torch.argmax(all_outputs, dim=1)
    accuracy   = (preds_cls == labels_1d).float().mean().item()

    # -------- 6. è®¡ç®— Macro-AUC --------
    probs      = torch.softmax(all_outputs, dim=1)
    one_hot    = torch.nn.functional.one_hot(labels_1d,
                                             num_classes=probs.shape[1]).float()
    auc_metric = ROCAUCMetric()
    auc_metric(y_pred=probs, y=one_hot)
    auc        = auc_metric.aggregate().item()

    print(f"\nâœ… Test ç»“æœ â†’  ACC: {accuracy:.4f} | AUC: {auc:.4f}")
    print("=====================================")



# ======================================================================================
# 5. ä¸»æ‰§è¡Œå‡½æ•°
# ======================================================================================
def main():
    config = Config()
    print("="*50)
    print(f"é…ç½®: Dataset={config.DATA_FLAG}, Model={config.MODEL_NAME}, Device={config.DEVICE}")
    print("="*50 + "\n")

    train_loader, val_loader, info, img_size = get_data_loaders(config)
    model = get_model(config, info, img_size)
    run_training(config, model, train_loader, val_loader, info)
    
    print("\næ‰€æœ‰ä»»åŠ¡å®Œæˆ!")

if __name__ == "__main__":
    main()
    evaluate_on_test(Config(), INFO[Config().DATA_FLAG],
                     img_size=(28, 28, 28))
