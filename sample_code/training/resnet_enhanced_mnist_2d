# 2D
# Dataset 3 - 2D Version
# v5 (Adapted from v4 for 2D Classification)
# Resnet - æœ€ç»ˆç‰ˆ (æ”¯æŒ ResNet50/101/18, EfficientNet, Swin Transformer)
# [ä¿®æ”¹] å·²æ•´åˆæ–¹æ¡ˆä¸€: ä½¿ç”¨ Accuracy + AUC çš„ç»¼åˆå¾—åˆ†æ¥æŒ‡å¯¼éªŒè¯
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from tqdm import tqdm
import torch.nn.functional as F

# å¯¼å…¥ MedMNIST å’Œ MONAI ç›¸å…³åº“
import medmnist
from medmnist import INFO, Evaluator

from monai.data import list_data_collate
from monai.transforms import (
    Compose,
    ScaleIntensityd,
    ToTensord,
    Resized,
    RandRotate90d,
    RandAffined,
    RandFlipd,
)
# [æ–°å¢] å¯¼å…¥ 2D æ¨¡å‹
from monai.networks.nets import ResNet, EfficientNetBN
from monai.metrics import ROCAUCMetric

# ======================================================================================
# 1. é…ç½®åŒºåŸŸ (å¯åœ¨æ­¤åˆ‡æ¢æ¨¡å‹)
# ======================================================================================
class Config:
    # --- å®éªŒä¸æ•°æ®é…ç½® ---
    # 'organsmnist', 'organamnist', 'organamnist', 'dermamnist', 'bloodmnist', etc.
    DATA_FLAG = 'organsmnist' 
    IMG_SIZE = (224, 224)

    # --- æ¨¡å‹é€‰æ‹© (åœ¨æ­¤å¤„ä¿®æ”¹ä»¥åˆ‡æ¢æ¨¡å‹) ---
    MODEL_NAME = 'ResNet50'          # é€‰é¡¹1: ResNet åŸºçº¿æ¨¡å‹
    # MODEL_NAME = 'ResNet18'          # é€‰é¡¹2: æ›´è½»é‡çš„ ResNet
    # MODEL_NAME = 'EfficientNet-B4'   # é€‰é¡¹3: é«˜æ•ˆçš„CNNæ¶æ„ (æ¨è)
    # MODEL_NAME = 'SwinTransformer'   # é€‰é¡¹4: å…ˆè¿›çš„Transformeræ¶æ„ (æ¨è)
    
    EXPERIMENT_NAME = f"{MODEL_NAME}_{DATA_FLAG}_{IMG_SIZE[0]}px_Final_CombinedMetric" # ä¸ºæœ¬æ¬¡å®éªŒå‘½å
    
    # --- è®­ç»ƒè¶…å‚æ•° ---
    NUM_EPOCHS = 30
    BATCH_SIZE = 64 # æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´, 224x224 å›¾åƒéœ€è¦æ›´å¤šæ˜¾å­˜
    LEARNING_RATE = 1e-4 # å¯¹äºå¤§æ¨¡å‹å’Œæ›´å¤§çš„å›¾åƒï¼Œç¨å°çš„å­¦ä¹ ç‡å¯èƒ½æ›´ç¨³å®š
    WEIGHT_DECAY = 1e-5
    
    # --- ç¡¬ä»¶ä¸æ•ˆç‡é…ç½® ---
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    NUM_WORKERS = 8 # æ ¹æ®æ‚¨çš„ç³»ç»Ÿé…ç½®è°ƒæ•´
    USE_AMP = True
    
    # --- æ¨¡å‹ä¿å­˜ ---
    MODEL_SAVE_DIR = "./saved_models_2d"

# ======================================================================================
# 2. è¾…åŠ©å‡½æ•° (æ•°æ®åŠ è½½å’Œæ¨¡å‹å®šä¹‰)
# ======================================================================================
class MedMNIST2DWrapper(Dataset):
    """ç”¨äºå°† MedMNIST æ•°æ®é›†åŒ…è£…æˆ MONAI å…¼å®¹æ ¼å¼çš„è¾…åŠ©ç±»"""
    def __init__(self, medmnist_dataset, transform):
        self.medmnist_dataset = medmnist_dataset
        self.transform = transform

    def __len__(self):
        return len(self.medmnist_dataset)

    def __getitem__(self, idx):
        image, label = self.medmnist_dataset[idx]
        # MedMNIST 2D æ•°æ®å·²ç»æ˜¯ (H, W, C) æˆ– (H, W)ï¼ŒMONAI éœ€è¦ (C, H, W)
        # np.transpose ä¼šå¤„ç†è¿™ä¸ªé—®é¢˜
        data = {'image': np.transpose(image, (2, 0, 1)), 'label': label}
        if self.transform:
            data = self.transform(data)
        return data

def get_data_loaders(config):
    """å‡†å¤‡å¹¶è¿”å›è®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨"""
    print(f"å‡†å¤‡æ•°æ®é›†: {config.DATA_FLAG}...")
    info = INFO[config.DATA_FLAG]
    # ä½¿ç”¨æ­£ç¡®çš„ MedMNIST æ•°æ®é›†ç±»
    DataClass = getattr(medmnist, info['python_class'])
    
    target_spatial_size = config.IMG_SIZE

    # 2D è®­ç»ƒæ•°æ®å¢å¼º
    train_transforms = Compose([
        ScaleIntensityd(keys="image"),
        Resized(keys="image", spatial_size=target_spatial_size, mode="bilinear", align_corners=False),
        RandFlipd(keys="image", spatial_axis=[0, 1], prob=0.5), # 2D ç¿»è½¬
        RandRotate90d(keys="image", prob=0.5, max_k=3),
        RandAffined(
            keys='image', mode='bilinear', prob=0.8, spatial_size=target_spatial_size,
            rotate_range=(np.pi / 18, np.pi / 18), # 2D æ—‹è½¬
            scale_range=(0.2, 0.2), padding_mode='border'
        ),
        ToTensord(keys=["image", "label"], track_meta=False),
    ])

    # 2D éªŒè¯/æµ‹è¯•æ•°æ®å˜æ¢
    val_test_transforms = Compose([
        ScaleIntensityd(keys="image"),
        Resized(keys="image", spatial_size=target_spatial_size, mode="bilinear", align_corners=False),
        ToTensord(keys=["image", "label"], track_meta=False),
    ])

    # ä¸‹è½½å¹¶åŒ…è£…æ•°æ®é›†
    train_dataset_raw = DataClass(split='train', download=True)
    train_ds = MedMNIST2DWrapper(train_dataset_raw, train_transforms)
    
    val_dataset_raw = DataClass(split='val', download=True)
    val_ds = MedMNIST2DWrapper(val_dataset_raw, val_test_transforms)

    # åˆ›å»º DataLoader
    train_loader = DataLoader(
        train_ds, batch_size=config.BATCH_SIZE, shuffle=True,  
        num_workers=config.NUM_WORKERS, collate_fn=list_data_collate, pin_memory=True
    )
    val_loader = DataLoader(
        val_ds, batch_size=config.BATCH_SIZE, shuffle=False,  
        num_workers=config.NUM_WORKERS, collate_fn=list_data_collate, pin_memory=True
    )
    
    print(f"æ•°æ®åŠ è½½å®Œæˆ. ä»»åŠ¡: {info['task']}, ç±»åˆ«æ•°: {len(info['label'])}, è¾“å…¥é€šé“: {info['n_channels']}")
    return train_loader, val_loader, info

def get_model(config, info):
    """æ ¹æ®é…ç½®åˆå§‹åŒ–å¹¶è¿”å›æ¨¡å‹"""
    model_name, num_classes = config.MODEL_NAME, len(info['label'])
    print(f"åˆå§‹åŒ–æ¨¡å‹: {model_name}...")
    in_channels = info['n_channels']
    
    # [æ ¸å¿ƒä¿®æ”¹] æ‰€æœ‰æ¨¡å‹çš„ `spatial_dims` éƒ½è®¾ç½®ä¸º 2
    if model_name == 'ResNet18':
        model = ResNet(layers=[2, 2, 2, 2], block='basic',
                       n_input_channels=in_channels, num_classes=num_classes, spatial_dims=2)
    
    elif model_name == 'ResNet50':
        model = ResNet(layers=[3, 4, 6, 3], block='bottleneck',
                       n_input_channels=in_channels, num_classes=num_classes, spatial_dims=2)
    
    elif model_name == 'ResNet101':
        model = ResNet(layers=[3, 4, 23, 3], block='bottleneck',
                       n_input_channels=in_channels, num_classes=num_classes, spatial_dims=2)

    elif model_name.startswith('EfficientNet'):
        model = EfficientNetBN(model_name=model_name.lower(), pretrained=False,
                               spatial_dims=2, in_channels=in_channels, num_classes=num_classes)
        
    elif model_name == 'SwinTransformer':
        model = SwinTransformer(
            in_chans=in_channels,
            num_classes=num_classes,
            img_size=config.IMG_SIZE, # 2D image size
            patch_size=(4, 4),        # 2D patch size
            window_size=(7, 7),       # 2D window size for 224x224
            depths=[2, 2, 6, 2],      # Swin-T (Tiny) config
            num_heads=[3, 6, 12, 24],
            use_v2=False,
        )

    else:
        raise ValueError(f"æ¨¡å‹ '{model_name}' ä¸è¢«æ”¯æŒ.")
        
    return model.to(config.DEVICE)


# ======================================================================================
# 3. è®­ç»ƒä¸è¯„ä¼°æ¨¡å—
# ======================================================================================
def run_training(config, model, train_loader, val_loader, info):
    """æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒå’ŒéªŒè¯æµç¨‹"""
    task = info['task']
    device = config.DEVICE

    loss_function = nn.CrossEntropyLoss() if 'multi-label' not in task else nn.BCEWithLogitsLoss()
    print(f"ä»»åŠ¡ä¸º {task}, ä½¿ç”¨ {loss_function.__class__.__name__}. ä¸»è¦è¯„ä¼°æŒ‡æ ‡: Combined Score (AUC + Accuracy).")
        
    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.NUM_EPOCHS, eta_min=1e-6)
    scaler = torch.cuda.amp.GradScaler(enabled=config.USE_AMP)
    
    # best_metric ç°åœ¨å°†å­˜å‚¨æœ€ä½³çš„ "ç»¼åˆå¾—åˆ†"
    best_metric, best_metric_epoch = -1, -1
    
    print(f"\n--- å¼€å§‹è®­ç»ƒ: {config.EXPERIMENT_NAME} ---")
    for epoch in range(config.NUM_EPOCHS):
        model.train()
        epoch_loss = 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config.NUM_EPOCHS} [è®­ç»ƒ]", unit="batch")
        for batch_data in progress_bar:
            inputs, labels = batch_data["image"].to(device, non_blocking=True), batch_data["label"].to(device, non_blocking=True)
            optimizer.zero_grad()
            
            with torch.cuda.amp.autocast(enabled=config.USE_AMP):
                outputs = model(inputs)
                if isinstance(loss_function, nn.CrossEntropyLoss):
                    labels = labels.squeeze(1).long()
                else:  
                    labels = labels.float()
                loss = loss_function(outputs, labels)
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            epoch_loss += loss.item()
            progress_bar.set_postfix({"loss": f"{loss.item():.4f}", "lr": f"{optimizer.param_groups[0]['lr']:.6f}"})
        
        scheduler.step()
        print(f"Epoch {epoch + 1} å¹³å‡è®­ç»ƒæŸå¤±: {epoch_loss / len(train_loader):.4f}")

        # --- éªŒè¯é€»è¾‘ ---
        model.eval()
        auc_metric = ROCAUCMetric()
        all_val_outputs, all_val_labels = [], []
        with torch.no_grad():
            for val_data in tqdm(val_loader, desc=f"Epoch {epoch+1}/{config.NUM_EPOCHS} [éªŒè¯]", unit="batch"):
                val_images = val_data["image"].to(device, non_blocking=True)
                val_labels = val_data["label"].to(device, non_blocking=True)
                with torch.cuda.amp.autocast(enabled=config.USE_AMP):
                    val_outputs = model(val_images)
                all_val_outputs.append(val_outputs)
                all_val_labels.append(val_labels)

        all_val_outputs = torch.cat(all_val_outputs, dim=0)
        all_val_labels = torch.cat(all_val_labels, dim=0)

        # è®¡ç®— Accuracy å’Œ AUC
        if 'multi-label' in task:
            val_probs = torch.sigmoid(all_val_outputs)
            auc_metric(y_pred=val_probs, y=all_val_labels.long())
            preds_class = val_probs > 0.5
            acc_result = (preds_class == all_val_labels.bool()).sum().item() / all_val_labels.numel()
        else: # å¤šåˆ†ç±»
            val_probs = torch.softmax(all_val_outputs, dim=1)
            val_labels_1d = all_val_labels.squeeze(1).long()
            num_classes = val_probs.shape[1]
            val_labels_onehot = F.one_hot(val_labels_1d, num_classes=num_classes).float()
            
            y_pred_classes = torch.argmax(all_val_outputs, dim=1)
            correct = (y_pred_classes == val_labels_1d).sum().item()
            acc_result = correct / val_labels_1d.numel()
            auc_metric(y_pred=val_probs, y=val_labels_onehot)
            
        auc_result = auc_metric.aggregate().item()

        # ======================= [æ ¸å¿ƒä¿®æ”¹] =======================
        # 1. è®¡ç®—ç»¼åˆå¾—åˆ† (ç®€å•ç›¸åŠ )
        combined_score = acc_result + auc_result

        print(f"Epoch {epoch + 1} éªŒè¯ -> AUC: {auc_result:.4f}, Accuracy: {acc_result:.4f}, Combined Score: {combined_score:.4f}")

        # 2. ä½¿ç”¨ "Combined Score" æ¥åˆ¤æ–­å’Œä¿å­˜æœ€ä½³æ¨¡å‹
        if combined_score > best_metric:
            best_metric, best_metric_epoch = combined_score, epoch + 1
            os.makedirs(config.MODEL_SAVE_DIR, exist_ok=True)
            save_path = os.path.join(config.MODEL_SAVE_DIR, f"best_{config.EXPERIMENT_NAME}.pth")
            torch.save(model.state_dict(), save_path)
            # 3. æ›´æ–°æç¤ºä¿¡æ¯
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! (åŸºäº Combined Score) å·²ä¿å­˜åˆ°: {save_path}")
        # ==========================================================

    print(f"--- è®­ç»ƒå®Œæˆ ---")
    print(f"æœ€ä½³éªŒè¯ Combined Score: {best_metric:.4f} (åœ¨ Epoch {best_metric_epoch})")

# ======================================================================================
# 4. Test é›†è¯„ä¼°
# ======================================================================================
@torch.no_grad()
def evaluate_on_test(config, info):
    """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ç»ˆä¿å­˜çš„æœ€ä½³æ¨¡å‹"""
    print("\n========== å¼€å§‹ Test è¯„ä¼° ==========")
    
    device = config.DEVICE
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®åŠ è½½å™¨
    test_transforms = Compose([
        ScaleIntensityd(keys="image"),
        Resized(keys="image", spatial_size=config.IMG_SIZE, mode="bilinear", align_corners=False),
        ToTensord(keys=["image", "label"], track_meta=False),
    ])

    DataClass = getattr(medmnist, info['python_class'])
    test_dataset_raw = DataClass(split="test", download=True)
    test_ds = MedMNIST2DWrapper(test_dataset_raw, test_transforms)

    test_loader = DataLoader(
        test_ds, batch_size=config.BATCH_SIZE, shuffle=False,
        num_workers=config.NUM_WORKERS, collate_fn=list_data_collate, pin_memory=True
    )

    # åŠ è½½æœ€ä½³æ¨¡å‹
    model = get_model(config, info)
    best_ckpt_path = os.path.join(config.MODEL_SAVE_DIR, f"best_{config.EXPERIMENT_NAME}.pth")
    
    if not os.path.exists(best_ckpt_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ '{best_ckpt_path}'ã€‚è¯·å…ˆå®Œæˆè®­ç»ƒã€‚")
        return

    model.load_state_dict(torch.load(best_ckpt_path, map_location=device))
    model.eval()

    # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ¨æ–­
    y_true = torch.tensor([], dtype=torch.long, device=device)
    y_score = torch.tensor([], device=device)

    for batch in tqdm(test_loader, desc="Test æ¨æ–­", unit="batch"):
        images = batch["image"].to(device, non_blocking=True)
        labels = batch["label"].to(device, non_blocking=True)
        with torch.cuda.amp.autocast(enabled=config.USE_AMP):
            outputs = model(images)

        y_true = torch.cat((y_true, labels), 0)
        y_score = torch.cat((y_score, outputs), 0)
    
    # ä½¿ç”¨ MedMNIST çš„ Evaluator è®¡ç®—å®˜æ–¹æŒ‡æ ‡
    y_true = y_true.squeeze().cpu().numpy()
    
    if 'multi-label' in info['task']:
        y_score = torch.sigmoid(y_score).cpu().numpy()
    else: # multi-class
        y_score = torch.softmax(y_score, dim=-1).cpu().numpy()
        
    evaluator = Evaluator(config.DATA_FLAG, 'test')
    metrics = evaluator.evaluate(y_score)
    
    acc = metrics['acc']
    auc = metrics['auc']

    print(f"\nâœ… Test ç»“æœ ({config.EXPERIMENT_NAME}) â†’ ACC: {acc:.4f} | AUC: {auc:.4f}")
    print("=====================================")


# ======================================================================================
# 5. ä¸»æ‰§è¡Œå‡½æ•°
# ======================================================================================
def main():
    """ä¸»å‡½æ•°ï¼Œç¼–æ’æ•´ä¸ªæµç¨‹"""
    config = Config()
    print("="*60)
    print(f"é…ç½®: Dataset={config.DATA_FLAG}, Model={config.MODEL_NAME}, Device={config.DEVICE}")
    print(f"å®éªŒåç§°: {config.EXPERIMENT_NAME}")
    print(f"è¶…å‚æ•°: Epochs={config.NUM_EPOCHS}, Batch Size={config.BATCH_SIZE}, LR={config.LEARNING_RATE}, AMP={'å¯ç”¨' if config.USE_AMP else 'ç¦ç”¨'}")
    print("="*60 + "\n")

    # å¼€å§‹è®­ç»ƒ
    train_loader, val_loader, info = get_data_loaders(config)
    model = get_model(config, info)
    run_training(config, model, train_loader, val_loader, info)
    
    # è®­ç»ƒç»“æŸåï¼Œè‡ªåŠ¨åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    evaluate_on_test(config, info)
    
    print("\næ‰€æœ‰ä»»åŠ¡å®Œæˆ!")

if __name__ == "__main__":
    # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥å…è®¸å¤šä¸ªOpenMPè¿è¡Œæ—¶ï¼Œé¿å…æ½œåœ¨çš„åº“å†²çª
    os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'
    main()
